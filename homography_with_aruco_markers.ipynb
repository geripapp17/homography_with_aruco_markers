{"cells":[{"cell_type":"markdown","metadata":{"id":"y9rE-0B2ZIIc"},"source":["# Homography with ArUco markers"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2267,"status":"ok","timestamp":1707038188272,"user":{"displayName":"Gergő Papp-Bálint","userId":"02290969456670062500"},"user_tz":-60},"id":"5fos716VZIIm","outputId":"60dc5ff4-0da8-44bc-91b8-50b1ee9fa391"},"outputs":[{"name":"stdout","output_type":"stream","text":["OpenCV version: 4.8.1\n"]}],"source":["from pathlib import Path\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from moviepy.editor import *\n","\n","print(f\"OpenCV version: {cv2.__version__}\")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n","marker_ids = [10, 17, 63, 50]  # Top Left, Top Right, Bottom Right, Bottom Left\n","BORDER_FRACTION = 1 / 5  # Size of the white border around the ArUco marker relative to the size of the marker\n","\n","video_dest_path = \"data/destination_video.mp4\"\n","video_src_path = \"data/source_video.mp4\"\n","output_path = f\"output/output_ar{Path(video_dest_path).suffix}\""]},{"cell_type":"markdown","metadata":{"id":"sJeSrs_1ZIIr"},"source":["## 00. Generate Markers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288},"executionInfo":{"elapsed":1736,"status":"ok","timestamp":1707038263152,"user":{"displayName":"Gergő Papp-Bálint","userId":"02290969456670062500"},"user_tz":-60},"id":"wcSHwlHeZIIt","outputId":"01d9aff7-85ef-4649-ff02-ce6e969be340"},"outputs":[],"source":["plt.figure(figsize=(18, 10))\n","for idx, marker_id in enumerate(marker_ids):\n","    marker = cv2.aruco.generateImageMarker(dictionary=aruco_dict, id=marker_id, sidePixels=200)\n","\n","    plt.subplot(1, len(marker_ids), idx + 1)\n","    plt.imshow(marker, cmap=\"gray\")\n","    plt.title(f\"Marker ID: {marker_ids[idx]}\")\n","    plt.axis(\"off\")\n","\n","    cv2.imwrite(f\"markers/marker_{marker_ids[idx]}.png\", marker)"]},{"cell_type":"markdown","metadata":{"id":"D_td-uSlZIIw"},"source":["## 01. Input Data"]},{"cell_type":"markdown","metadata":{},"source":["### 01.1 Display Destination Video"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8IFIO4zOZIIy","outputId":"b9dd5dc6-fe6a-42d0-9a47-3fce65efc909"},"outputs":[],"source":["clip = VideoFileClip(filename=video_dest_path)\n","clip.ipython_display(width=1000)"]},{"cell_type":"markdown","metadata":{},"source":["### 01.2 Display Source Video"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iEVszSeSZIIz","outputId":"51e00371-17dc-4914-d74a-9a25288f7b51"},"outputs":[],"source":["# Display source video\n","clip = VideoFileClip(filename=video_src_path)\n","clip.ipython_display(width=1000)"]},{"cell_type":"markdown","metadata":{},"source":["### 01.3 Read Video Files"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"1zwnk6fEZII0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Width: 1920\tHeight: 1080\tFPS: 25\n"]}],"source":["video_cap_dest = cv2.VideoCapture(video_dest_path)\n","if not video_cap_dest.isOpened():\n","    print(f\"Error opening video stream or file: {video_dest_path}\")\n","\n","video_cap_src = cv2.VideoCapture(video_src_path)\n","if not video_cap_src.isOpened():\n","    print(f\"Error opening video stream or file: {video_src_path}\")\n","\n","assert video_cap_dest.isOpened() and video_cap_src.isOpened()\n","\n","fps = int(video_cap_dest.get(cv2.CAP_PROP_FPS))\n","frame_width = int(video_cap_dest.get(cv2.CAP_PROP_FRAME_WIDTH))\n","frame_height = int(video_cap_dest.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","print(f\"Width: {frame_width}\\tHeight: {frame_height}\\tFPS: {fps}\")"]},{"cell_type":"markdown","metadata":{"id":"1gShq_vdZII2"},"source":["## 02. Output Data"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"xe3FrB5AZII3"},"outputs":[],"source":["fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n","video_writer = cv2.VideoWriter(output_path, fourcc, fps, (2 * frame_width, frame_height))"]},{"cell_type":"markdown","metadata":{"id":"vY22edLeZII3"},"source":["## 03. Processing frames"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"2juFyvkXZII4"},"outputs":[],"source":["from typing import List\n","from numpy.typing import NDArray\n","\n","\n","def extract_points(marker_ids: List[int], ids: NDArray, corners: NDArray) -> NDArray:\n","    \"\"\"\n","    Function for extracting Region Of Interest (ROI) from destination video.\n","\n","    Args:\n","        marker_ids:\n","            Marker IDs which were used during capturing the destination video.\n","        ids:\n","            Detected marker ids.\n","        corners:\n","            Corners of all detected markers.\n","\n","    Returns:\n","        List containing the 4 corner coordinates of ROI in the destination video.\n","    \"\"\"\n","\n","    points = []\n","\n","    for marker_idx, marker_id in enumerate(marker_ids):\n","        idx = np.squeeze(np.where(ids == marker_id))\n","        marker_corners = np.squeeze(corners[idx])\n","\n","        marker_width = abs(marker_corners[0][0] - marker_corners[1][0]) + 10\n","        marker_height = abs(marker_corners[0][1] - marker_corners[2][1]) + 10\n","\n","        if marker_idx == 0:  # Top Left\n","            point = marker_corners[0] + [-marker_width * BORDER_FRACTION, -marker_height * BORDER_FRACTION]\n","        elif marker_idx == 1:  # Top Right\n","            point = marker_corners[1] + [marker_width * BORDER_FRACTION, -marker_height * BORDER_FRACTION]\n","        elif marker_idx == 2:  # Bottom Right\n","            point = marker_corners[2] + [marker_width * BORDER_FRACTION, marker_height * BORDER_FRACTION]\n","        elif marker_idx == 3:  # Bottom Left\n","            point = marker_corners[3] + [-marker_width * BORDER_FRACTION, marker_height * BORDER_FRACTION]\n","\n","        points.append(point)\n","\n","    return np.asarray(points)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"z_6J8AX3ZII5","outputId":"45662c4b-7fea-4bdc-d643-9bd2a9473ceb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing frames ...\n","Finished processing frames ...\n"]}],"source":["print(\"Processing frames ...\")\n","while True:\n","    # Read frames until the end of the source or destination video\n","    has_frame, frame_dest = video_cap_dest.read()\n","    if not has_frame:\n","        break\n","\n","    has_frame, frame_src = video_cap_src.read()\n","    if not has_frame:\n","        break\n","\n","    # Detect markers\n","    corners, ids, rejected = cv2.aruco.detectMarkers(image=frame_dest, dictionary=aruco_dict)\n","\n","    # Extract ROI corners from marker corners\n","    points_dest = extract_points(marker_ids=marker_ids, ids=np.squeeze(ids), corners=corners)\n","\n","    # Corners of source video\n","    points_src = np.asarray(\n","        [[0, 0], [frame_src.shape[1], 0], [frame_src.shape[1], frame_src.shape[0]], [0, frame_src.shape[0]]]\n","    )\n","\n","    # Calculate the homography matrix\n","    h, mask = cv2.findHomography(srcPoints=points_src, dstPoints=points_dest, method=cv2.RANSAC)\n","\n","    # Warp source image onto the destination image\n","    warped_image = cv2.warpPerspective(frame_src, h, (frame_dest.shape[1], frame_dest.shape[0]))\n","\n","    # Create ROI mask which is used to add the source video to the destination video\n","    mask = np.zeros([frame_dest.shape[0], frame_dest.shape[1]], dtype=np.uint8)\n","    cv2.fillConvexPoly(mask, np.int32([points_dest]), 1, cv2.LINE_AA)\n","    mask_BGR = cv2.merge([mask, mask, mask])\n","\n","    # Create black region in destination frame ROI.\n","    frame_masked = frame_dest * (1 - mask_BGR)\n","\n","    frame_result = cv2.bitwise_or(warped_image, frame_masked)\n","    frame_out = cv2.hconcat([frame_dest, frame_result])\n","\n","    frame_out = cv2.line(\n","        img=frame_out,\n","        pt1=(int(frame_out.shape[1] / 2), 0),\n","        pt2=(int(frame_out.shape[1] / 2), frame_out.shape[0]),\n","        color=(255, 255, 255),\n","        thickness=8,\n","    )\n","\n","    video_writer.write(frame_out)\n","\n","print(\"Finished processing frames ...\")\n","video_writer.release()"]},{"cell_type":"markdown","metadata":{"id":"Otkn4z0GZII7"},"source":["## 04. Display Result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ONMohmjzZII7","outputId":"f447dfc2-4a8c-4e2f-93ac-76433d307afc"},"outputs":[],"source":["clip = VideoFileClip(filename=output_path)\n","clip.ipython_display(width=2000)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"computer_vision","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
